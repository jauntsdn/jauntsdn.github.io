<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Message-Streams</title>

		<meta name="description" content="Message-Streams: universal communication for applications on JVM">
		<meta name="author" content="Maksym Ostroverkhov">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		
		<link rel="icon" href="/favicon.png">
		<link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Flex:wght@300&display=swap" rel="stylesheet">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/white.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="plugin/highlight/zenburn.css">

		<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-159301973-1"></script>
            <script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments)};
              gtag('js', new Date());
              gtag('config', 'UA-159301973-1');
        </script> -->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<a href="https://jauntsdn.com">
						<img src="message-streams/mstreams.png" alt="message-streams logo" style="height: 35px; margin: 0 auto 2rem auto; background: transparent;" class="demo-logo">
					</a>
					<h2>Message-Streams</h2>
					<h7>universal communication for JVM applications</h7>
					<p>
						<small></small>
					</p>
					<p>
						<small>🇺🇦 Maksym Ostroverkhov</small>
					</p>
					<p>
						<small>jauntsdn.github.io / mostroverkhov@gmail / ostroverkhov@twitter / mostroverkhov@github</small>
					</p>
				</section>
                <section>
					<a href="https://jauntsdn.com">
						<img src="message-streams/mstreams.png" alt="message-streams logo" style="height: 35px; margin: 0 auto 2rem auto; background: transparent;" class="demo-logo">
					</a>
					<h2>MESSAGE-STREAMS</h2>
					<p>&nbsp</p>
					<p>⚡very fast GRPC-like services on JVM with rich streaming model over multiple network transports</p>
				</section>
				<section>
					<a href="https://jauntsdn.com">
						<img src="message-streams/mstreams.png" alt="message-streams logo" style="height: 35px; margin: 0 auto 2rem auto; background: transparent;" class="demo-logo">
					</a>
					<p>Popular data format: <span style="color:#2196f3">Protocol Buffers</span>.</p>
					<p>Familiar workflow & tooling: <span style="color:#2196f3">GRPC</span>.</p>
					<p>Much <span style="color:#2196f3">faster</span>, with several transports:</p>
				    <p><h7>🌐 bytestream: TCP, VM & unix sockets; internet: GRPC, websockets (http1+http2), http/json transcoding</h7></p>
					<p><h7>🌐 internet transports: multiprotocol - any combo on single port; multitransport - any bytestream transport.</h7></p>
				</section>
				<section>
					<a href="https://jauntsdn.com">
						<img src="message-streams/mstreams.png" alt="message-streams logo" style="height: 35px; margin: 0 auto 2rem auto; background: transparent;" class="demo-logo">
					</a>
					<p>~ 🇬 Compatible, similar to & callable by GRPC, but:</p>
					<p><span style="color:#2196f3">+ Multiple transports.</span></p>
					<p><span style="color:#2196f3">+ Much better throughput/latency.</span></p>
					<p><span style="color:#2196f3">+ Lower Garbage production.</span></p>
					<p><span style="color:#2196f3">+ Smaller wire size/binary footprint.</span></p>
					<p><span style="color:#2196f3">+ Built-in load estimation/balancing.</span></p>
					<p><span style="color:#2196f3">+ Resumable sessions.</span></p>
					<p><span style="color:#2196f3">+ Neutral.</span></p>
					<p>&nbsp;</p>
				</section>
				<section>
					<h2>TL;DR</h2>
					<ul>
						<li>⚡lean & very fast: millions messages/core, million of simultaneous streams on with commodity PC</li>
						<li>multiple APIs: ☕CompletableFutures & virt. threads; 🌊streaming with grpc-api, reactor, rxjava, mutiny</li>
						<li>pluggable networking: ⚡tcp, vm & unix sockets; 🌐grpc, websockets, websockets-over-http2</li>
						<li>☁️service APIs/codegen stubs [Message-Streams] are split from library runtime [RSocket-JVM]</li>
						<li>☁️transparent origin [RPC] & proxy load estimation for cpu-efficient load balancers</li>
						<li>☁️native image support with graalvm</li>
					</ul>
				</section>
                <section>
					<h2>Message-Streams: API</h2>
					<p>set of interactions with composable message streams</p>
					<p>🌊flow control ⚠️error handling 🚫cancellation</p>
					<ul>
						<li>request-response 1:1</li>
						<li>request-stream 1:n</li>
						<li>request-channel n:n, n:1</li>
						<li>fire-and-forget 1:0 - latency is not important</li>
					</ul>
				</section>
				<section>
					<h2>Message-Streams: GRPC API</h2>
					<p>set of interactions with composable message streams</p>
					<p>🌊flow control ⚠️error handling 🚫cancellation</p>
					<pre><code data-trim data-noescape><script type="text/template">
									public interface MessageStreams extends Closeable {
			
										void fireAndForget(Message message, StreamObserver<Message> observer);
									  
										void requestResponse(Message message, StreamObserver<Message> observer);
									  
										void requestStream(Message message, StreamObserver<Message> observer);
									  
										StreamObserver<Message> requestChannel(StreamObserver<Message> observer);
									  
										Optional<Message.Factory> messageFactory();
									}
								</script></code></pre>
				</section>
				<section>
					<section>
						<h2>Message-Streams: Reactive Streams API</h2>
						<p>set of interactions with composable message streams</p>
						<p>🌊flow control ⚠️error handling 🚫cancellation</p>
						<pre><code data-trim data-noescape><script type="text/template">
										public interface MessageStreams extends Closeable {
				
											Publisher<Void> fireAndForget(Message message);
										  
											Publisher<Message> requestResponse(Message message);
										  
											Publisher<Message> requestStream(Message message);
										  
											Publisher<Message> requestChannel(Publisher<Message> msgs);
										  
											Optional<Message.Factory> messageFactory();
										}
									</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams</h2>
						<p>Smallrye-mutiny from Quarkus / RedHat</p>
						<pre><code data-trim data-noescape><script type="text/template">
										public interface MessageStreams extends Closeable {
				
											Uni<Void> fireAndForget(Message message);
										  
											Uni<Message> requestResponse(Message message);
										  
											Multi<Message> requestStream(Message message);
										  
											Multi<Message> requestChannel(Publisher<Message> msgs);
										}
									</script></code></pre>
									<img src="message-streams/smallrye-logo.svg" height="100px">
					</section>
					<section>
						<h2>Message-Streams</h2>
						<p>Project-reactor from SpringBoot / Vmware</p>
						<pre><code data-trim data-noescape><script type="text/template">
										public interface MessageStreams extends Closeable {
				
											Mono<Void> fireAndForget(Message message);
										  
											Mono<Message> requestResponse(Message message);
										  
											Flux<Message> requestStream(Message message);
										  
											Flux<Message> requestChannel(Publisher<Message> msgs);
										}
									</script></code></pre>
									<img src="message-streams/reactor-logo.png" height="100px">
					</section>
					<section>
						<h2>Message-Streams</h2>
						<p>Rxjava3 from ReactiveX</p>
						<pre><code data-trim data-noescape><script type="text/template">
										public interface MessageStreams extends Closeable {
				
											Completable fireAndForget(Message message);
										  
											Single<Message> requestResponse(Message message);
										  
											Flowable<Message> requestStream(Message message);
										  
											Flowable<Message> requestChannel(Publisher<Message> msgs);
										}
									</script></code></pre>
									<img src="message-streams/rxjava-logo.png" height="80px">
					</section>
					<section>
						<h2>Message-Streams: message</h2>
						<p>binary data with optional metadata</p>
						<pre><code data-trim data-noescape><script type="text/template">
							abstract class Message extends AbstractReferenceCounted {

								abstract ByteBuf metadata();
							  
								abstract ByteBuf data();
							  
								abstract ByteBuf content();
			    }
						</script></code></pre>
					</section>
				</section>
				<section>
					<h2>Message-Streams: FUTURES API</h2>
					<p>subset of non-streaming interactions</p>
					<p>CompletableFuture from Jdk8 ☕</p>
					<pre><code data-trim data-noescape><script type="text/template">
									public interface MessageStreams extends Closeable {
			
										CompletionStage<Void> fireAndForget(Message message);
									  
										CompletionStage<Message> requestResponse(Message message);
									}
								</script></code></pre>
				</section>
                <section>
					<h2>Message-Streams: VIRTUAL THREADS</h2>
					<p>subset of non-streaming interactions</p>
					<p>much cheaper* blocking with Jdk21 ☕ virtual threads</p>
					<pre><code data-trim data-noescape><script type="text/template">
									public interface MessageStreams extends Closeable {
			
										void fireAndForget(Message message);
									  
										Message requestResponse(Message message);
									}
								</script></code></pre>
				</section>
				<section>
					<section>
						<h2>Message-Streams: RPC</h2>
						<ul>
							<li>🇬 Protobuf/codegen RPC system on top of Message-Streams</li>
							<li>🇬 GRPC compatibility</li>
							<li>🇬 GRPC-like devexp: schema, compiler, client/server stubs</li>
							<li>🔧request ranks, idempotent requests</li>
							<li>🔧 non-opinionated instrumentation: prometheus, micrometer OOTB</li>
							<li>🌊 virtual threads & completablefuture; GRPC-stubs; smallrye-mutiny, project-reactor, rxjava3</li>
						</ul>
					</section>
					<section>
						<h2>Message-Streams: RPC schema</h2>
						<p>Protobuf service 📄API definition</p>
						<pre><code data-trim data-noescape><script type="text/template">
							service RpcService {

								rpc reply (Request) returns (Response) {}
								rpc serverStream (Request) returns (stream Response) {}
								rpc clientStream (stream Request) returns (Response) {}
								rpc channel (stream Request) returns (stream Response) {}
								rpc fnf (Request) returns (google.protobuf.Empty) {
									option (io.rsocket.rpc.options) = {
										  fire_and_forget: true
										  rank: 1
										  idempotent: true
									};
								}
							}
						</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: RPC codegen stubs</h2>
						<p>RPC-compiler generated service 📄API</p>
						<pre><code data-trim data-noescape><script type="text/template">
							public interface Service {

							  Mono<Response> reply(Request message, Headers metadata);
							
							  Flux<Response> serverStream(Request message, Headers metadata);
							
							  Mono<Response> clientStream(Publisher<Request> messages, Headers metadata);
							
							  Flux<Response> channel(Publisher<Request> messages, Headers metadata);
							
							  Mono<Void> fnf(Request message, Headers metadata);
							}					
						</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: RPC codegen stubs</h2>
						<p>Message metadata📄</p>
						<pre><code data-trim data-noescape><script type="text/template">
							public final class Headers {
								final List<String> keyValues;
							}					
						</script></code></pre>
						<p>List of ASCII key-values</p>
						<p>Protocol Buffers on wire</p>
					</section>
					<section>
						<h2>Message-Streams: RPC codegen stubs</h2>
						<p>RPC-compiler generated client & server stubs</p>
						<pre><code data-trim data-noescape><script type="text/template">
							ServiceClient /*implements Service*/ client =
							     ServiceClient
								    .create(MessageStreams, 
								            /*RpcInstrumentation*/Optional.empty());					
							
							ServiceServer /*implements MessageStreams*/ server = 
							     ServiceServer
								    .create(Service,
									          /*RpcInstrumentation*/Optional.empty())
									  .withLifecycle(MessageStreams);						  
						</script></code></pre>
					</section>
				</section>
				<section>
					<h2>Message-Streams: RPC</h2>
					<p>Interop demo. Kitchen application services</p>
					<a href="https://github.com/jauntsdn/rsocket-jvm-interop-examples">
						https://github.com/jauntsdn/rsocket-jvm-interop-examples
					</a>
					<ul>
						<li>🌾Farmer: Mstreams-RPC-reactor / TCP</li>
						<li>📄Recipes: Mstreams-RPC-futures / TCP</li>
						<li>🧑‍🍳Roundsman: Mstreams-RPC-mutiny / ws-http2</li>
						<li>👨‍🍳Chef: Mstreams-RPC-GRPC-stubs / unix sockets</li>
						<li>🔪Kitchen: Mstreams-RPC-rxjava / GRPC</li>
						<li>🍽️Gourmet: GRPC/grpc-java client</li>
					</ul>
				</section>
                <!-- vert: scheme, gen if, client ,server, client/server acceptor(symmetric) -->
					<section>
						<h2>Message-Streams: runtime</h2>
						<a href="https://jauntsdn.com">
							<img src="message-streams/rsocket-logo.svg" alt="rsocket logo"
								style="height: 100px; margin: 0 auto 0rem auto; background: transparent;" class="demo-logo">
						</a>
						<p>extended alternative: JAUNTSDN / RSocket-JVM</p>
						<a href="https://jauntsdn.com">
							<img src="message-streams/jaunt-logo-text.png" alt="rsocket logo"
								style="height: 75px; margin: 0rem auto 0rem auto; background: transparent;" class="demo-logo">
						</a>
					</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>Jauntsdn / RSocket-JVM</h2>
						<p>⚡ alternative to RSocket/RSocket-java</p>
						<p>of reactive.foundation [🪦 fall 2021]</p>
						<p>MOTIVATIONS</p>
						<ul>
							<li>⛔ bad perf: convoluted internals, dropped ball on RPC, use reflection for data<a href="#/19">[1]</a></li>
							<li>⛔ vulnerabilities: 4 trivial denial-of-service cases<a href="#/19">[2]</a></li>
							<li>⛔ no reusable parts for other vendor API, 🍃Spring libs only: reactor/reactor-netty, micrometer
							</li>
						</ul>
					</section>
					<section>
						<h2>RSocket / RSocket-java</h2>
						<h2>Vulnerabilities</h2>
						<p>by reactive.foundation [🪦 fall 2021]</p>
						<ul>
							<li>⛔ D-O-S: FD exhaustion, memory overflow <a href="#/19">[2]</a></li>
							<li>⛔ 3 of 4 interactions: request-response, request-stream, request-channel</li>
							<li>⛔ last release: early Jun 2021</li>
						</ul>
						<p><small></small></p>
						<p>🍃 team as main 📣, adopter & maintainer: 🙈🙉🙊
					</section>
				</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>RSocket protocol</h2>
						<ul>
							<li>
								⚡low latency/high throughput L5 protocol
								intended for high-performance services communication
							</li>
							<li>
								symmetric interactions, 2 peers may start requests
							</li>
							<li>
								🌐 transport agnostic, runs on top of any reliable byte stream transport
							</li>
							<li>
								🌊 superset of Message-Streams 
							</li>
						</ul>
						<pre><code data-trim data-noescape><script type="text/template">
										public interface RSocket extends MessageStreams {
										  Publisher<Void> metadataPush(Message metadata);
										  double availability(int requestRank);
										}					
									</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: API, RPC</h2>
						<p>🌊flow control ⚠️error handling 🚫cancellation</p>
						<pre><code data-trim data-noescape><script type="text/template">
							🌊Publisher<Message> stream(Message request);
							🌊Publisher<Message> channel(Publisher<Message> request);
						</script></code></pre>
						<pre><code data-trim data-noescape><script type="text/template">
							☕CompletableFuture<Message> response(Message request);
						</script></code></pre>
						<pre><code data-trim data-noescape><script type="text/template">
							Message => 🇬com.google.protobuf.MessageLite => 🇬GRPC
						</script></code></pre>
						<h2>RSocket-JVM: runtime</h2>
						<p>🏃 runtime: networking, transports - datacenter & internet</p>
						<p>☁️ features: load estimation/circuit breaking, load balancing, real graceful close</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>Jauntsdn / RSocket-JVM</h2>
						<ul>
							<li>
								⚡high perf, tiny garbage production,
								may serve 1 million streams with commodity PC
							</li>
							<li>
								🌐 transports: TCP, unix sockets, websockets-over-http2, 🇬 GRPC compatibility
							</li>
							<li>
								☁️ requests leasing: circuit breaking,
								adaptive latency-based load estimation for lightweight load balancing
							</li>
							<li>
								☁️ request ranks: keep critical services under load, driven by responder with request leasing 
							</li>
						</ul>
					</section>
					<section>
						<ul>
							<li>
								☁️ scalable keep-alives, lightweight coarse scheduler for timeouts
							</li>
							<li>
								☁️ graceful shutdown: client & server
							</li>
							<li>
								☁️ non-opinionated metrics: prometheus, micrometer OOTB
							</li>
							<li>
								☁️ symmetric interactions
							</li>
						</ul>
						<pre><code data-trim data-noescape><script type="text/template">
										public interface ServerStreamsAcceptor {
											Mono<MessageStreams> accept(SetupMessage setup, 
												                          MessageStreams requester);
										}					
				
										public interface ClientStreamsAcceptor {
											MessageStreams accept(SetupMessage setup, 
											                      MessageStreams requester);
										}
									</script></code></pre>
					</section>
				</section>
				<section>
					<h2>Message-Streams: runtime</h2>
					<h2>Jauntsdn / RSocket-JVM core</h2>
					<p>♻️ Protocol core is shared by vendor libs: mutiny, reactor etc</p>
					<ul>
						<li>
							☮️♻️ components: framing, handshakes, keep-alives, requests leasing, 
							graceful close, error handling etc	
						</li>
						<li>
							☮️ tiny & neutral: netty-buffer is only dependency	
						</li>
						<li>
							☮️♻️ modules: transports, load estimators, metrics
						</li>
					</ul>
				</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>Network transports</h2>
						<p>🌐 Internet transports (TLS) may share same port: websockets, websockets-http2, GRPC, http/json</p>
					</section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>Network transports</h2>
						<p>☁️ JSON transcoding: selected services can be served as http/json</p>
						<p>Control plane, health endpoint etc</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>request leasing</h2>
						<p>⏳🎫Responder: time limited request credit: allow (duration, requests, rank)</p>
						<ul>
							<li>Circuit breaking: responder driven / requester aware</li>
							<li>Responder: request stats</li>
							<li>Credit = f(svc latency stats/ success rate + RTT)</li>
							<li>Duration (interval): cap requests rate</li>
							<li>Lease = credit + request rank: service brownout</li>
							<li>Requester: RSocket.availability(rank) [0 ; 1]</li>
						</ul>
					</section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>leasing: stats</h2>
						<pre><code data-trim data-noescape><script type="text/template">
							public interface /*Lease.*/StatsRecorder<T> {
								T onRequestStarted(Type requestType, ByteBuf metadata);
								void onResponseStarted(Type requestType, T request,
									StreamSignal firstSignal, long latencyMicros);
								void onResponseTerminated(Type requestType, T request,
									StreamSignal lastSignal, long responseDurationMicros);
								void onRtt(long rttMicros);
							}
						</script></code></pre>
						<pre><code data-trim data-noescape><script type="text/template">
							public interface /*Lease.*/Controller {
								void allow(int timeToLiveMillis, 
								           int allowedRequests, 
								           int rank);
							}
						</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>leasing: load balancing</h2>
						<ul>
							<li>📖theory: min(set(RSocket.availability)) + conn RTT</li>
							<li>🔨practice: more complex - still cpu-efficient</li>
							<li>LB + lease: CPU utilization + connection RTT</li>
							<li>LB + lease metadata: allowed fnf, indicative service latencies</li>
							<li>service latency: call hash + latency</li>
						</ul>
					</section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<p>RPC origin lease: latency based load estimator</p>
						<pre><code data-trim data-noescape><script type="text/template">
										Lease.Configurer loadLimiter =
										RSocketLoadLimiter.create()
											.rSocketEstimator(() -> new AimdRSocketEstimator(
											     TARGET_RTT /*1*/, BACKOFF_RATIO /*0.9*/, 
												 UTILIZATION_RATIO /*0.5*/, ERROR_RATIO /*0.2*/))
											.serviceEstimator(limit -> new AimdServiceEstimator(
											      limit.latencyMillis(), BACKOFF_RATIO /*0.9*/,
												   STEP /*3*/))
											.serviceLimits(RSocketRpcLimits.create()
													.limit(Service.SERVICE, Service.METHOD_RESPONSE, 
													        LATENCY_MILLIS /*35*/, LATENCY_CAP /*100*/)
													.build())
											.initialAllowedRequests(100)
											.build();		
									</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<p>RPC origin lease: latency based load estimator</p>
						<ul>
							<li>AIMD: additive inc⬆️ / multiplicative dec⬇️</li>
							<li>service ⬅️response latency</li>
							<li>🔄RTT latency</li>
							<li>⚠️error rate</li>
							<li>♨️CPU / memory utilization</li>
							<li>♨️leased capacity utilization</li>
						</ul>
					</section>
				</section>
				<section>
					<h2>Message-Streams: RPC</h2>
					<p>Interop demo. Kitchen application services</p>
					<a href="https://github.com/jauntsdn/rsocket-jvm-interop-examples">
						https://github.com/jauntsdn/rsocket-jvm-interop-examples
					</a>
					<ul>
						<li>🌾Farmer: Mstreams-RPC-reactor / TCP</li>
						<li>📄Recipes: Mstreams-RPC-futures / TCP</li>
						<li>🧑‍🍳Roundsman: Mstreams-RPC-mutiny / ws-http2</li>
						<li>👨‍🍳Chef: Mstreams-RPC-grpc-stubs / unix sockets</li>
						<li>🔪Kitchen: Mstreams-RPC-rxjava / GRPC</li>
						<li>🍽️Gourmet: GRPC/grpc-java client</li>
					</ul>
				</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>RPC througput test</h2>
						<p>⚡Single vCPU RYZEN™ 5 2600X, reactor, non-TLS, TCP EPOLL /w linux 5.4.0, jdk11</p>
						<table>
							<tr>
								<th>msg size, bytes</th>
								<th>8</th>
								<th>128</th>
								<th>512</th>
							</tr>
							<tr>
								<td>request-response</td>
								<td>1.45mil</td>
								<td>1.0mil</td>
								<td>0.55mil</td>
							</tr>
							<tr>
								<td>request-stream</td>
								<td>3.3mil</td>
								<td>2.4mil</td>
								<td>0.9mil</td>
							</tr>
							<tr>
								<td>request-channel</td>
								<td>3.5mil</td>
								<td>2.4mil</td>
								<td>1.25mil</td>
							</tr>
						</table>
					</section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>GRPC-RPC througput test</h2>
						<p>🦥GRPC-java client, MStreams RPC server. Single vCPU RYZEN™ 5 2600X, reactor, non-TLS, TCP EPOLL /w linux 5.4.0, jdk11</p>
						<table>
							<tr>
								<th>msg size, bytes</th>
								<th>8</th>
							</tr>
							<tr>
								<td>request-response</td>
								<td>0.1mil</td>
							</tr>
							<tr>
								<td>request-stream</td>
								<td>1.4mil</td>
							</tr>
							<tr>
								<td>request-channel</td>
								<td>1.2mil</td>
							</tr>
						</table>
					</section>
				</section>
				<section>
					<section>
						<h2>Message-Streams: runtime</h2>
						<h2>Load test</h2>
						<p>♨️♨️1 million streams, 10k conns, single host <a href="#/19">[3]</a></p>
						<ul>
							<li>Host: 16 vCPU / 32gb RAM, linux 5.4.0, jdk11</li>
							<li>Scheduler: Nomad/Consul</li> 
							<li>1 server: 8vCPU/16gb, 2 clients: 4vCPU/8gb each</li>
							<li>TCP non-TLS /w EPOLL IO</li>
						</ul>
					</section>
					<section>
						<h2>Server, simultaneous streams</h2>
						<p>♨️1 million streams over 10k connections, monotonically over ~16 mins</p>
						<img src="message-streams/1000k-streams-part2.png" alt="1 mill streams"
						style="margin: 0 auto 0rem auto; background: transparent;" class="demo-logo">
					</section>
					<section>
						<h2>Host CPU usage</h2>
						<p>♨️server: 60% of host CPU, 85% overall used by load test</p>
						<img src="message-streams/1000k-cpu-part2.png" alt="1 mill streams"
						style="margin: 0 auto 0rem auto; background: transparent;" class="demo-logo">
					</section>
					<section>
						<h2>Server, memory alloc rate</h2>
						<p>❄️Peaks at only 50 Mb/sec => 50 bytes per inbound message</p>
						<img src="message-streams/1000k-alloc-part2.png" alt="1 mill streams"
						style="margin: 0 auto 0rem auto; background: transparent;" class="demo-logo">
					</section>
				</section>
				<section>
					<section>
						<h2>Message-Streams: RPC</h2>
						<h2>Size & start time</h2>
						<p>☕CompletableFutures: 1st request time & binaries size</p>
						<table>
							<tr>
								<th>app</th>
								<th>TCP/-TLS</th>
								<th>websocket-http2/+TLS</th>
							</tr>
							<tr>
								<td>svc size</td>
								<td>2.9MB</td>
								<td>2.9MB</td>
							</tr>
							<tr>
								<td>app size</td>
								<td>5.3MB</td>
								<td>7.7MB</td>
							</tr>
							<tr>
								<td>1st request ⏳</td>
								<td>350 ms</td>
								<td>600 ms</td>
							</tr>
						</table>
						<ul>
							<li>svc: netty 0.9MB, protobuf 1.7MB - room for 🔧</li>
						</ul>
					</section>
					<section>
						<h2>Message-Streams: RPC</h2>
						<h2>Distribution size</h2>
						<p>☕CompletableFutures: application image (/w JRE17) & alpine docker image size</p>
						<table>
							<tr>
								<th>app</th>
								<th>TCP</th>
								<th>websocket-http2/TLS</th>
							</tr>
							<tr>
								<td>App JRE image</td>
								<td>49.5MB</td>
								<td>51.9MB</td>
							</tr>
							<tr>
								<td>App alpine 📦</td>
								<td>57MB</td>
								<td>59.4MB</td>
							</tr>
						</table>
					</section>
					<section>
						<h2>Message-Streams: RPC</h2>
						<h2>Native binary size</h2>
						<p>☕CompletableFutures: native executable /w Graalvm11, serial GC </p>
						<ul>
							<li>⚡TCP native binary size: 20.5MB, startup: instant</li>
						</ul>
					</section>
				</section>
				<!-- <section>
					<section>
						<h2>Message-Streams: Proxy</h2>
						<p>Important goal: min overhead for proxy usecase</p>
						<ul>
							<li>🤖Prototype: service broker / proxy</li>
							<li>🤖Prototype: split Message-Streams / Runtime</li>
							<li>🤖Prototype: 🏃runnable demo</li>	
						</ul>
						<p><small></small></p>
						<p>service [requester, responder]</p>
						<p>↕️service broker↕️</p>
						<p>service [requester, responder]</p>
					</section>
					<section>
						<h2>Message-Streams: Proxy</h2>
						<p>🤖Prototype: service broker</p>
						<pre><code data-trim data-noescape><script type="text/template">
							Disposable server =
							new PlatformServer()
								.instance("local")
								.platformAddress(
									/*bind*/new InetSocketAddress("localhost", 9091), 
									/*advertise*/new InetSocketAddress("localhost", 9091))
								.start()
								.block();
					
    				server.onClose().await();
						</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: Proxy</h2>
						<p>🤖Prototype: service requester</p>
						<pre><code data-trim data-noescape><script type="text/template">
						PlatformService platformService =
					        PlatformService.create(configFile)
					            .service(
					                serviceClient -> {
					                  StreamService service =
					                     StreamServiceClient.create(
											 				 	 serviceClient.service("service"));
					                  Request request = Request.newBuilder()
									     					.setMessage("data").build();
					                  service.serverStream(request)
									    					.subscribe(new StreamSubscriber());
					                  return /*request handler*/Optional.empty();
					                });
					
						new PlatformServiceRuntime(/*instance*/ "local")
					        .connect(platformService)
					        .flatMap(Closeable::onClose)
					        .block();
											</script></code></pre>
					</section>
					<section>
						<h2>Message-Streams: Proxy</h2>
						<p>🤖Prototype: service responder</p>
						<pre><code data-trim data-noescape><script type="text/template">
						PlatformService platformService =
							PlatformService.create(configFile)
								.service(
									serviceClient ->
										Optional.of(
											StreamServiceServer.create(
												new DefaultStreamService())));
					
						new PlatformServiceRuntime("local" /*instance*/)
							.connect(platformService)
							.flatMap(Closeable::onClose)
							.block();	
						</script></code></pre>
					</section>
				</section> -->
				<section>
					<h2>Summary</h2>
					<ul>
						<li>⚡lean & very fast (millions messages/core) GRPC-like services on JVM with rich streaming model</li>
						<li>multiple APIs: ☕CompletableFuture; 🌊streaming with reactor, rxjava, mutiny, grpc-stubs</li>
						<li>pluggable networking: ⚡tcp, unix sockets; 🌐grpc, websockets-over-http2</li>
						<li>☁️service APIs/codegen stubs [Message-Streams] are split from library runtime [RSocket-JVM]</li>
						<li>☁️transparent origin [RPC] & proxy load estimation which enables cpu-efficient load balancers</li>
						<li>☁️native image support with graalvm</li>
					</ul>
				</section>
				<section>
					<a href="https://jauntsdn.com">
						<img src="message-streams/mstreams.png" alt="message-streams logo" style="height: 35px; margin: 0 auto 2rem auto; background: transparent;" class="demo-logo">
					</a>
					<h2>Questions</h2>
					<small>jauntsdn.com / mostroverkhov@gmail / ostroverkhov@twitter / mostroverkhov@github</small>
				</section>
				<section>
					<h2>References</h2>
					<p style="text-align: left;">
						<small>
							<a href="https://jauntsdn.github.io/post/rsocket-million-streams-2/">
							[1] https://jauntsdn.github.io/post/rsocket-million-streams-2/</a>
						</small>
					</p>
					<p style="text-align: left;">
						<small>
                            <a href="https://github.com/spring-projects/spring-framework/issues/27373">
								[2] https://github.com/spring-projects/spring-framework/issues/27373
							</a> 
						</small>
					</p>
					<p style="text-align: left;">
						<small>
							<a href="https://github.com/spring-projects/spring-framework/issues/27427">
								&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://github.com/spring-projects/spring-framework/issues/27427
							</a>
						</small>
					</p>
					<p style="text-align: left;">
						<small>
							<a href="https://github.com/spring-projects/spring-framework/issues/27428">
								&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://github.com/spring-projects/spring-framework/issues/27428
							</a>
						</small>
					</p>
					<p style="text-align: left;">
						<small>
							<a href="https://github.com/spring-projects/spring-framework/issues/27462">
								&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://github.com/spring-projects/spring-framework/issues/27462
							</a>
						</small>
					</p>
					<p style="text-align: left;">
						<small>
							<a href="https://jauntsdn.github.io/post/rsocket-million-streams-1/">
								[3] https://jauntsdn.github.io/post/rsocket-million-streams-1/
							</a>
						</small>
					</p>
				</section>
			</div>

		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/zoom/zoom.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/search/search.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>

			// Also available as an ES module, see:
			// https://revealjs.com/initialization/
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight ]
			});

		</script>

	</body>
</html>
